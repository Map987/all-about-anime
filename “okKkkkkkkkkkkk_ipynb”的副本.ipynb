{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Map987/all-about-anime/blob/main/%E2%80%9CokKkkkkkkkkkkk_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMLNjIxZ4Nwr",
        "outputId": "0066c395-43fb-45bb-8214-c4dc474ed394",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'download-anime-mag-'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 88 (delta 14), reused 0 (delta 0), pack-reused 61\u001b[K\n",
            "Unpacking objects: 100% (88/88), 2.60 MiB | 4.54 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Map987/download-anime-mag-.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y6FG_-J34boZ",
        "outputId": "f651b16c-5876-4859-bd82-4d1f15754239",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folders = [\"/content/sample_data/outputtxt\", \"/content/sample_data/outtxt\", \"/content/sample_data/imagebig/\"]\n",
        "for folder in folders:\n",
        "    os.makedirs(folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "IhdnHQxv4YBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "from typing import List\n",
        "\n",
        "def extract_links(xml_string: str) -> List[str]:\n",
        "    root = ET.fromstring(xml_string)\n",
        "    links = []\n",
        "    for url in root.findall('{http://www.sitemaps.org/schemas/sitemap/0.9}url'):\n",
        "        image_loc = url.find('{http://www.google.com/schemas/sitemap-image/1.1}image').find('{http://www.google.com/schemas/sitemap-image/1.1}loc').text\n",
        "        if image_loc:\n",
        "            links.append(image_loc)\n",
        "    return links"
      ],
      "metadata": {
        "id": "MCNkHReC4orR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_links_to_file(file_path: str, links: List[str]) -> None:\n",
        "    with open(file_path, 'w') as f:\n",
        "        for link in links:\n",
        "            f.write(link)"
      ],
      "metadata": {
        "id": "_9N6QNac4rxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = '/content/download-anime-mag-/'\n",
        "output_folder = '/content/sample_data/outputtxt/'\n",
        "\n",
        "for file_name in os.listdir(input_folder):\n",
        "    if file_name.endswith('.xml'):\n",
        "        input_path = os.path.join(input_folder, file_name)\n",
        "        with open(input_path, 'r') as f:\n",
        "            xml_string = f.read()\n",
        "        links = extract_links(xml_string)\n",
        "        output_path = os.path.join(output_folder, file_name[:-4] + '.txt')\n",
        "        write_links_to_file(output_path, links)\n",
        "        print(f'{output_path} written successfully.\\n')"
      ],
      "metadata": {
        "id": "4vIBCHGO4voj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "input_folder_path = '/content/sample_data/outputtxt/'\n",
        "output_folder_path = '/content/sample_data/outtxt/'\n",
        "\n",
        "# get all .txt files in input folder\n",
        "files = [f for f in os.listdir(input_folder_path) if os.path.isfile(os.path.join(input_folder_path, f)) and f.endswith('.txt')]\n",
        "\n",
        "for file_name in files:\n",
        "    # open input file\n",
        "    input_file_path = os.path.join(input_folder_path, file_name)\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        file_content = input_file.read()\n",
        "\n",
        "    # add newline before each https\n",
        "    file_content = file_content.replace('https://', 'https://')\n",
        "\n",
        "    # create output file\n",
        "    output_file_path = os.path.join(output_folder_path, file_name)\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        output_file.write(file_content)"
      ],
      "metadata": {
        "id": "PduZW4YQ4zUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "outtxt_dir = \"/content/sample_data/outtxt\"\n",
        "data_dir = \"/content/sample_data/\"\n",
        "\n",
        "# 遍历outtxt_dir目录中的所有txt文件\n",
        "for filename in os.listdir(outtxt_dir):\n",
        "    if filename.endswith(\".txt\") and filename.startswith(\"image-sitemap-\"):\n",
        "        # 获取X值\n",
        "        x = filename.split(\"-\")[-1].split(\".\")[0]\n",
        "        \n",
        "        # 创建imageX文件夹\n",
        "        folder = os.path.join(data_dir, f\"image{x}\")\n",
        "        os.makedirs(folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "66PtkiDb40ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "def download(url, output_folder_path):\n",
        "    response = requests.get(url)\n",
        "    file_name = os.path.basename(url)\n",
        "    file_path = os.path.join(output_folder_path, file_name)\n",
        "\n",
        "    with open(file_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "        print(f\"File {file_name} downloaded successfully.\")\n",
        "\n",
        "def process_txt(x):\n",
        "    url_file_path = f\"/content/sample_data/outtxt/image-sitemap-{x}.txt\"\n",
        "    output_folder_path = f\"/content/sample_data/image{x}/\"\n",
        "    destination_folder = '/content/sample_data/imagebig'\n",
        "\n",
        "    try:\n",
        "        with open(url_file_path, 'r') as url_file:\n",
        "            file_content = url_file.read()\n",
        "\n",
        "            urls = file_content.split('https')\n",
        "            urls = ['https' + url for url in urls if url.endswith('.jpg') or url.endswith('.png')]\n",
        "\n",
        "            count = len(urls)\n",
        "            with ThreadPoolExecutor(max_workers=64) as executor:\n",
        "                futures = [executor.submit(download, url, output_folder_path) for url in urls]\n",
        "                for future in as_completed(futures):\n",
        "                    future.result()\n",
        "\n",
        "        print(f\"Downloaded {count} files for image{x}.\")\n",
        "\n",
        "        source_folder = output_folder_path\n",
        "        destination_folder = os.path.join(destination_folder, '')\n",
        "        zip_filename = f\"image{x}.zip\"\n",
        "        zip_filepath = os.path.join(destination_folder, zip_filename)\n",
        "\n",
        "        with zipfile.ZipFile(zip_filepath, 'w') as myzip:\n",
        "            for filename in os.listdir(source_folder):\n",
        "                file_path = os.path.join(source_folder, filename)\n",
        "                myzip.write(file_path, filename)\n",
        "\n",
        "        print(\"Files have been successfully zipped for image{x} to\", zip_filepath)\n",
        "\n",
        "        source_file = zip_filepath\n",
        "        destination_folder = '/content/drive/MyDrive'\n",
        "\n",
        "        shutil.copy(source_file, destination_folder)\n",
        "        print(f\"Zip file for image{x} has been successfully copied to Google Drive folder.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url_file_path}: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    txt_files = list(range(6, 58)) + ['55_1', '25_1', '57_1']\n",
        "\n",
        "    for file in txt_files:\n",
        "        print(f\"Processing image{file}:\")\n",
        "        process_txt(file)"
      ],
      "metadata": {
        "id": "ej76ZF9PBtcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "def download(url, output_folder_path):\n",
        "    response = requests.get(url)\n",
        "    file_name = os.path.basename(url)\n",
        "    file_path = os.path.join(output_folder_path, file_name)\n",
        "\n",
        "    with open(file_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "        print(f\"File {file_name} downloaded successfully.\")\n",
        "\n",
        "def process_txt(x):\n",
        "    if x in range(10, 24):\n",
        "        print(f\"Skipping image{x} as it is in exclusion list.\")\n",
        "        return\n",
        "\n",
        "    url_file_path = f\"/content/sample_data/outtxt/image-sitemap-{x}.txt\"\n",
        "    output_folder_path = f\"/content/sample_data/image{x}/\"\n",
        "    destination_folder = '/content/sample_data/imagebig'\n",
        "\n",
        "    try:\n",
        "        with open(url_file_path, 'r') as url_file:\n",
        "            file_content = url_file.read()\n",
        "\n",
        "            urls = file_content.split('https')\n",
        "            urls = ['https' + url for url in urls if url.endswith('.jpg') or url.endswith('.png')]\n",
        "\n",
        "            count = len(urls)\n",
        "            with ThreadPoolExecutor(max_workers=64) as executor:\n",
        "                futures = [executor.submit(download, url, output_folder_path) for url in urls]\n",
        "                for future in as_completed(futures):\n",
        "                    future.result()\n",
        "\n",
        "        print(f\"Downloaded {count} files for image{x}.\")\n",
        "\n",
        "        source_folder = output_folder_path\n",
        "        destination_folder = os.path.join(destination_folder, '')\n",
        "        zip_filename = f\"image{x}.zip\"\n",
        "        zip_filepath = os.path.join(destination_folder, zip_filename)\n",
        "\n",
        "        with zipfile.ZipFile(zip_filepath, 'w') as myzip:\n",
        "            for filename in os.listdir(source_folder):\n",
        "                file_path = os.path.join(source_folder, filename)\n",
        "                myzip.write(file_path, filename)\n",
        "\n",
        "        print(\"Files have been successfully zipped for image{x} to\", zip_filepath)\n",
        "\n",
        "        source_file = zip_filepath\n",
        "        destination_folder = '/content/drive/MyDrive'\n",
        "\n",
        "        shutil.copy(source_file, destination_folder)\n",
        "        print(f\"Zip file for image{x} has been successfully copied to Google Drive folder.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url_file_path}: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    txt_files = list(range(6, 58)) + ['25_1', '55_1', '57_1']\n",
        "\n",
        "    for file in txt_files:\n",
        "        print(f\"Processing image{file}:\")\n",
        "        process_txt(file)"
      ],
      "metadata": {
        "id": "NspQQlOSGQAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 遍历文件夹中的所有文本文件并读取全部内容\n",
        "extensions = []\n",
        "for filename in os.listdir('/content/sample_data/outtxt/'):\n",
        "    if filename.endswith('.txt'):\n",
        "        with open('/content/sample_data/outtxt/' + filename, 'r') as file:\n",
        "            file_content = file.read()\n",
        "            # 获取所有链接中的文件拓展名\n",
        "            for link in file_content.split('https'):\n",
        "                ext = os.path.splitext(link)[1][1:]\n",
        "                if ext:\n",
        "                    extensions.append(ext.lower())\n",
        "\n",
        "# 输出所有的文件格式\n",
        "print(\"所有的文件格式:\")\n",
        "for ext in set(extensions):\n",
        "    print(ext)"
      ],
      "metadata": {
        "id": "nO6VgpaWRK1J",
        "outputId": "a1c93b69-d7a5-4b21-e616-24dfdd96deef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "所有的文件格式:\n",
            "jpg\n",
            "tif\n",
            "png\n",
            "webp\n",
            "gif\n",
            "jpeg\n",
            "bmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "\n",
        "def download(url, output_folder_path):\n",
        "    response = requests.get(url)\n",
        "    file_name = os.path.basename(url)\n",
        "    file_path = os.path.join(output_folder_path, file_name)\n",
        "\n",
        "    with open(file_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "        print(f\"File {file_name} downloaded successfully.\")\n",
        "\n",
        "\n",
        "def process_txt(x):\n",
        "    url_file_path = f\"/content/sample_data/outtxt/image-sitemap-{x}.txt\"\n",
        "    output_folder_path = f\"/content/sample_data/image{x}/\"\n",
        "    destination_folder = '/content/sample_data/imagebig'\n",
        "\n",
        "    try:\n",
        "        with open(url_file_path, 'r') as url_file:\n",
        "            file_content = url_file.read()\n",
        "\n",
        "            urls = file_content.split('https')\n",
        "            urls = ['https' + url for url in urls if url.endswith('.tif') or url.endswith('.webp')]\n",
        "\n",
        "            count = len(urls)\n",
        "            with ThreadPoolExecutor(max_workers=64) as executor:\n",
        "                futures = [executor.submit(download, url, output_folder_path) for url in urls]\n",
        "                for future in as_completed(futures):\n",
        "                    future.result()\n",
        "\n",
        "        print(f\"Downloaded {count} files for image{x}.\")\n",
        "\n",
        "        source_folder = output_folder_path\n",
        "        destination_folder = os.path.join(destination_folder, '')\n",
        "        zip_filename = f\"image{x}.zip\"\n",
        "        zip_filepath = os.path.join(destination_folder, zip_filename)\n",
        "\n",
        "        with zipfile.ZipFile(zip_filepath, 'w') as myzip:\n",
        "            for filename in os.listdir(source_folder):\n",
        "                file_path = os.path.join(source_folder, filename)\n",
        "                myzip.write(file_path, filename)\n",
        "\n",
        "        print(\"Files have been successfully zipped for image{x} to\", zip_filepath)\n",
        "\n",
        "        source_file = zip_filepath\n",
        "        destination_folder = '/content/drive/MyDrive'\n",
        "\n",
        "        shutil.copy(source_file, destination_folder)\n",
        "        print(f\"Zip file for image{x} has been successfully copied to Google Drive folder.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url_file_path}: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    txt_files = list(range(1, 58)) + ['25_1', '55_1', '57_1', ]\n",
        "\n",
        "    for file in txt_files:\n",
        "        print(f\"Processing image{file}:\")\n",
        "        process_txt(file)"
      ],
      "metadata": {
        "id": "GcIIaAXfROwz",
        "outputId": "34026358-e680-4c1a-8d3e-916cdcbccb60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image1:\n",
            "Downloaded 0 files for image1.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-1.txt: [Errno 2] No such file or directory: '/content/sample_data/image1/'\n",
            "Processing image2:\n",
            "Downloaded 0 files for image2.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-2.txt: [Errno 2] No such file or directory: '/content/sample_data/image2/'\n",
            "Processing image3:\n",
            "Downloaded 0 files for image3.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-3.txt: [Errno 2] No such file or directory: '/content/sample_data/image3/'\n",
            "Processing image4:\n",
            "Downloaded 0 files for image4.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-4.txt: [Errno 2] No such file or directory: '/content/sample_data/image4/'\n",
            "Processing image5:\n",
            "Downloaded 0 files for image5.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-5.txt: [Errno 2] No such file or directory: '/content/sample_data/image5/'\n",
            "Processing image6:\n",
            "Downloaded 0 files for image6.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-6.txt: [Errno 2] No such file or directory: '/content/sample_data/image6/'\n",
            "Processing image7:\n",
            "Downloaded 0 files for image7.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-7.txt: [Errno 2] No such file or directory: '/content/sample_data/image7/'\n",
            "Processing image8:\n",
            "Downloaded 0 files for image8.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-8.txt: [Errno 2] No such file or directory: '/content/sample_data/image8/'\n",
            "Processing image9:\n",
            "Downloaded 0 files for image9.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-9.txt: [Errno 2] No such file or directory: '/content/sample_data/image9/'\n",
            "Processing image10:\n",
            "Downloaded 0 files for image10.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-10.txt: [Errno 2] No such file or directory: '/content/sample_data/image10/'\n",
            "Processing image11:\n",
            "Downloaded 0 files for image11.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-11.txt: [Errno 2] No such file or directory: '/content/sample_data/image11/'\n",
            "Processing image12:\n",
            "Downloaded 0 files for image12.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-12.txt: [Errno 2] No such file or directory: '/content/sample_data/image12/'\n",
            "Processing image13:\n",
            "Downloaded 0 files for image13.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-13.txt: [Errno 2] No such file or directory: '/content/sample_data/image13/'\n",
            "Processing image14:\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-14.txt: [Errno 2] No such file or directory: '/content/sample_data/image14/MR01_Still021_20191224.tif'\n",
            "Processing image15:\n",
            "Downloaded 0 files for image15.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-15.txt: [Errno 2] No such file or directory: '/content/sample_data/image15/'\n",
            "Processing image16:\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-16.txt: [Errno 2] No such file or directory: '/content/sample_data/image16/4d136f760fdc1f7f65103f8f3fc29f38.tif'\n",
            "Processing image17:\n",
            "Downloaded 0 files for image17.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-17.txt: [Errno 2] No such file or directory: '/content/sample_data/image17/'\n",
            "Processing image18:\n",
            "Downloaded 0 files for image18.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-18.txt: [Errno 2] No such file or directory: '/content/sample_data/image18/'\n",
            "Processing image19:\n",
            "Downloaded 0 files for image19.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-19.txt: [Errno 2] No such file or directory: '/content/sample_data/image19/'\n",
            "Processing image20:\n",
            "Downloaded 0 files for image20.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-20.txt: [Errno 2] No such file or directory: '/content/sample_data/image20/'\n",
            "Processing image21:\n",
            "Downloaded 0 files for image21.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-21.txt: [Errno 2] No such file or directory: '/content/sample_data/image21/'\n",
            "Processing image22:\n",
            "Downloaded 0 files for image22.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-22.txt: [Errno 2] No such file or directory: '/content/sample_data/image22/'\n",
            "Processing image23:\n",
            "Downloaded 0 files for image23.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-23.txt: [Errno 2] No such file or directory: '/content/sample_data/image23/'\n",
            "Processing image24:\n",
            "Downloaded 0 files for image24.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-24.txt: [Errno 2] No such file or directory: '/content/sample_data/image24/'\n",
            "Processing image25:\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-25.txt: [Errno 2] No such file or directory: '/content/sample_data/outtxt/image-sitemap-25.txt'\n",
            "Processing image26:\n",
            "Downloaded 0 files for image26.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-26.txt: [Errno 2] No such file or directory: '/content/sample_data/image26/'\n",
            "Processing image27:\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-27.txt: [Errno 2] No such file or directory: '/content/sample_data/image27/0d11370c7c793ae9425ffcf3fa3c69ef.tif'\n",
            "Processing image28:\n",
            "Downloaded 0 files for image28.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-28.txt: [Errno 2] No such file or directory: '/content/sample_data/image28/'\n",
            "Processing image29:\n",
            "Downloaded 0 files for image29.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-29.txt: [Errno 2] No such file or directory: '/content/sample_data/image29/'\n",
            "Processing image30:\n",
            "Downloaded 0 files for image30.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-30.txt: [Errno 2] No such file or directory: '/content/sample_data/image30/'\n",
            "Processing image31:\n",
            "Downloaded 0 files for image31.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-31.txt: [Errno 2] No such file or directory: '/content/sample_data/image31/'\n",
            "Processing image32:\n",
            "Downloaded 0 files for image32.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-32.txt: [Errno 2] No such file or directory: '/content/sample_data/image32/'\n",
            "Processing image33:\n",
            "Downloaded 0 files for image33.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-33.txt: [Errno 2] No such file or directory: '/content/sample_data/image33/'\n",
            "Processing image34:\n",
            "Downloaded 0 files for image34.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-34.txt: [Errno 2] No such file or directory: '/content/sample_data/image34/'\n",
            "Processing image35:\n",
            "Downloaded 0 files for image35.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-35.txt: [Errno 2] No such file or directory: '/content/sample_data/image35/'\n",
            "Processing image36:\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-36.txt: [Errno 2] No such file or directory: '/content/sample_data/image36/52a2655488b56108c6153c50671b2bb2.tif'\n",
            "Processing image37:\n",
            "Downloaded 0 files for image37.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-37.txt: [Errno 2] No such file or directory: '/content/sample_data/image37/'\n",
            "Processing image38:\n",
            "Downloaded 0 files for image38.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-38.txt: [Errno 2] No such file or directory: '/content/sample_data/image38/'\n",
            "Processing image39:\n",
            "Downloaded 0 files for image39.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-39.txt: [Errno 2] No such file or directory: '/content/sample_data/image39/'\n",
            "Processing image40:\n",
            "Downloaded 0 files for image40.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-40.txt: [Errno 2] No such file or directory: '/content/sample_data/image40/'\n",
            "Processing image41:\n",
            "Downloaded 0 files for image41.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-41.txt: [Errno 2] No such file or directory: '/content/sample_data/image41/'\n",
            "Processing image42:\n",
            "Downloaded 0 files for image42.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-42.txt: [Errno 2] No such file or directory: '/content/sample_data/image42/'\n",
            "Processing image43:\n",
            "Downloaded 0 files for image43.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-43.txt: [Errno 2] No such file or directory: '/content/sample_data/image43/'\n",
            "Processing image44:\n",
            "Downloaded 0 files for image44.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-44.txt: [Errno 2] No such file or directory: '/content/sample_data/image44/'\n",
            "Processing image45:\n",
            "Downloaded 0 files for image45.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-45.txt: [Errno 2] No such file or directory: '/content/sample_data/image45/'\n",
            "Processing image46:\n",
            "Downloaded 0 files for image46.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-46.txt: [Errno 2] No such file or directory: '/content/sample_data/image46/'\n",
            "Processing image47:\n",
            "Downloaded 0 files for image47.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-47.txt: [Errno 2] No such file or directory: '/content/sample_data/image47/'\n",
            "Processing image48:\n",
            "Downloaded 0 files for image48.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-48.txt: [Errno 2] No such file or directory: '/content/sample_data/image48/'\n",
            "Processing image49:\n",
            "Downloaded 0 files for image49.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-49.txt: [Errno 2] No such file or directory: '/content/sample_data/image49/'\n",
            "Processing image50:\n",
            "Downloaded 0 files for image50.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-50.txt: [Errno 2] No such file or directory: '/content/sample_data/image50/'\n",
            "Processing image51:\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-51.txt: [Errno 2] No such file or directory: '/content/sample_data/image51/0a5a3d44de1dfe3e8daa798f4b23e408.webp'\n",
            "Processing image52:\n",
            "Downloaded 0 files for image52.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-52.txt: [Errno 2] No such file or directory: '/content/sample_data/image52/'\n",
            "Processing image53:\n",
            "Downloaded 0 files for image53.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-53.txt: [Errno 2] No such file or directory: '/content/sample_data/image53/'\n",
            "Processing image54:\n",
            "Downloaded 0 files for image54.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-54.txt: [Errno 2] No such file or directory: '/content/sample_data/image54/'\n",
            "Processing image55:\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-55.txt: [Errno 2] No such file or directory: '/content/sample_data/outtxt/image-sitemap-55.txt'\n",
            "Processing image56:\n",
            "Downloaded 0 files for image56.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-56.txt: [Errno 2] No such file or directory: '/content/sample_data/image56/'\n",
            "Processing image57:\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-57.txt: [Errno 2] No such file or directory: '/content/sample_data/outtxt/image-sitemap-57.txt'\n",
            "Processing image25_1:\n",
            "Downloaded 0 files for image25_1.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-25_1.txt: [Errno 2] No such file or directory: '/content/sample_data/image25_1/'\n",
            "Processing image55_1:\n",
            "Downloaded 0 files for image55_1.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-55_1.txt: [Errno 2] No such file or directory: '/content/sample_data/image55_1/'\n",
            "Processing image57_1:\n",
            "Downloaded 0 files for image57_1.\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-57_1.txt: [Errno 2] No such file or directory: '/content/sample_data/image57_1/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "\n",
        "def download(url, output_folder_path):\n",
        "    response = requests.get(url)\n",
        "    file_name = os.path.basename(url)\n",
        "    file_path = os.path.join(output_folder_path, file_name)\n",
        "\n",
        "    with open(file_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "        print(f\"File {file_name} downloaded successfully.\")\n",
        "\n",
        "\n",
        "def process_txt(x):\n",
        "    url_file_path = f\"/content/sample_data/outtxt/image-sitemap-{x}.txt\"\n",
        "    output_folder_path = f\"/content/sample_data/imagebig/jpeg\"\n",
        "\n",
        "    try:\n",
        "        with open(url_file_path, 'r') as url_file:\n",
        "            file_content = url_file.read()\n",
        "\n",
        "            urls = file_content.split('https')\n",
        "            urls = ['https' + url for url in urls if url.endswith('.tif') or url.endswith('.webp')]\n",
        "\n",
        "            count = len(urls)\n",
        "            with ThreadPoolExecutor(max_workers=64) as executor:\n",
        "                futures = [executor.submit(download, url, output_folder_path) for url in urls]\n",
        "                for future in as_completed(futures):\n",
        "                    future.result()\n",
        "\n",
        "        print(f\"Downloaded {count} files for image{x}.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url_file_path}: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    txt_files = list(range(1, 58)) + ['25_1', '55_1', '57_1', ]\n",
        "\n",
        "    for file in txt_files:\n",
        "        print(f\"Processing image{file}:\")\n",
        "        process_txt(file)"
      ],
      "metadata": {
        "id": "Zf_WMR-PRxV1",
        "outputId": "d5999f59-ec61-49e9-ee0b-b2a09a14bdfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image1:\n",
            "Downloaded 0 files for image1.\n",
            "Processing image2:\n",
            "Downloaded 0 files for image2.\n",
            "Processing image3:\n",
            "Downloaded 0 files for image3.\n",
            "Processing image4:\n",
            "Downloaded 0 files for image4.\n",
            "Processing image5:\n",
            "Downloaded 0 files for image5.\n",
            "Processing image6:\n",
            "Downloaded 0 files for image6.\n",
            "Processing image7:\n",
            "Downloaded 0 files for image7.\n",
            "Processing image8:\n",
            "Downloaded 0 files for image8.\n",
            "Processing image9:\n",
            "Downloaded 0 files for image9.\n",
            "Processing image10:\n",
            "Downloaded 0 files for image10.\n",
            "Processing image11:\n",
            "Downloaded 0 files for image11.\n",
            "Processing image12:\n",
            "Downloaded 0 files for image12.\n",
            "Processing image13:\n",
            "Downloaded 0 files for image13.\n",
            "Processing image14:\n",
            "File MR01_Still021_20191224.tif downloaded successfully.\n",
            "File MR01_Still004_20191224.tif downloaded successfully.\n",
            "Downloaded 2 files for image14.\n",
            "Processing image15:\n",
            "Downloaded 0 files for image15.\n",
            "Processing image16:\n",
            "File 4d136f760fdc1f7f65103f8f3fc29f38-1.tif downloaded successfully.\n",
            "File 4d136f760fdc1f7f65103f8f3fc29f38.tif downloaded successfully.\n",
            "Downloaded 2 files for image16.\n",
            "Processing image17:\n",
            "Downloaded 0 files for image17.\n",
            "Processing image18:\n",
            "Downloaded 0 files for image18.\n",
            "Processing image19:\n",
            "Downloaded 0 files for image19.\n",
            "Processing image20:\n",
            "Downloaded 0 files for image20.\n",
            "Processing image21:\n",
            "Downloaded 0 files for image21.\n",
            "Processing image22:\n",
            "Downloaded 0 files for image22.\n",
            "Processing image23:\n",
            "Downloaded 0 files for image23.\n",
            "Processing image24:\n",
            "Downloaded 0 files for image24.\n",
            "Processing image25:\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-25.txt: [Errno 2] No such file or directory: '/content/sample_data/outtxt/image-sitemap-25.txt'\n",
            "Processing image26:\n",
            "Downloaded 0 files for image26.\n",
            "Processing image27:\n",
            "File 0d11370c7c793ae9425ffcf3fa3c69ef.tif downloaded successfully.\n",
            "Downloaded 1 files for image27.\n",
            "Processing image28:\n",
            "Downloaded 0 files for image28.\n",
            "Processing image29:\n",
            "Downloaded 0 files for image29.\n",
            "Processing image30:\n",
            "Downloaded 0 files for image30.\n",
            "Processing image31:\n",
            "Downloaded 0 files for image31.\n",
            "Processing image32:\n",
            "Downloaded 0 files for image32.\n",
            "Processing image33:\n",
            "Downloaded 0 files for image33.\n",
            "Processing image34:\n",
            "Downloaded 0 files for image34.\n",
            "Processing image35:\n",
            "Downloaded 0 files for image35.\n",
            "Processing image36:\n",
            "File ac7f5b706b02f5c6f4a2613e7cab7066.tif downloaded successfully.\n",
            "File 572870def83bef73a46e056699ceaa9b.tif downloaded successfully.\n",
            "File 689847edb3fa28122951d5a1aa638482.tif downloaded successfully.\n",
            "File 52a2655488b56108c6153c50671b2bb2.tif downloaded successfully.\n",
            "File e9d2aba0c8f4a52f23a489e4f117f12e.tif downloaded successfully.File 7f7880fb42f3272de229a7611d7f510e.tif downloaded successfully.\n",
            "\n",
            "File ce99a1e0bce43d622651b4b779bccc5f.tif downloaded successfully.\n",
            "File 05ae34bd495e0457cef805d5eba3902a.tif downloaded successfully.\n",
            "Downloaded 8 files for image36.\n",
            "Processing image37:\n",
            "Downloaded 0 files for image37.\n",
            "Processing image38:\n",
            "Downloaded 0 files for image38.\n",
            "Processing image39:\n",
            "Downloaded 0 files for image39.\n",
            "Processing image40:\n",
            "Downloaded 0 files for image40.\n",
            "Processing image41:\n",
            "Downloaded 0 files for image41.\n",
            "Processing image42:\n",
            "Downloaded 0 files for image42.\n",
            "Processing image43:\n",
            "Downloaded 0 files for image43.\n",
            "Processing image44:\n",
            "Downloaded 0 files for image44.\n",
            "Processing image45:\n",
            "Downloaded 0 files for image45.\n",
            "Processing image46:\n",
            "Downloaded 0 files for image46.\n",
            "Processing image47:\n",
            "Downloaded 0 files for image47.\n",
            "Processing image48:\n",
            "Downloaded 0 files for image48.\n",
            "Processing image49:\n",
            "Downloaded 0 files for image49.\n",
            "Processing image50:\n",
            "Downloaded 0 files for image50.\n",
            "Processing image51:\n",
            "File 0a5a3d44de1dfe3e8daa798f4b23e408.webp downloaded successfully.\n",
            "Downloaded 1 files for image51.\n",
            "Processing image52:\n",
            "Downloaded 0 files for image52.\n",
            "Processing image53:\n",
            "Downloaded 0 files for image53.\n",
            "Processing image54:\n",
            "Downloaded 0 files for image54.\n",
            "Processing image55:\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-55.txt: [Errno 2] No such file or directory: '/content/sample_data/outtxt/image-sitemap-55.txt'\n",
            "Processing image56:\n",
            "Downloaded 0 files for image56.\n",
            "Processing image57:\n",
            "Error processing /content/sample_data/outtxt/image-sitemap-57.txt: [Errno 2] No such file or directory: '/content/sample_data/outtxt/image-sitemap-57.txt'\n",
            "Processing image25_1:\n",
            "Downloaded 0 files for image25_1.\n",
            "Processing image55_1:\n",
            "Downloaded 0 files for image55_1.\n",
            "Processing image57_1:\n",
            "Downloaded 0 files for image57_1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "source_dir = '/content/sample_data/imagebig/jpeg'\n",
        "target_zip = '/content/drive/MyDrive/tif.zip'\n",
        "\n",
        "try:\n",
        "    # Create a zip file to write to\n",
        "    with shutil.make_archive(os.path.splitext(target_zip)[0], 'zip', source_dir) as zip_file:\n",
        "        print(f\"Compressed {source_dir} into {zip_file}.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error compressing {source_dir}: {e}\")"
      ],
      "metadata": {
        "id": "bvPFcoCQSBDg",
        "outputId": "88cd4736-1099-4ee6-f62d-66fc6d87a363",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error compressing /content/sample_data/imagebig/jpeg: __enter__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_txt(x):\n",
        "    url_file_path = f\"/content/sample_data/outtxt/image-sitemap-{x}.txt\"\n",
        "    output_folder_path = f\"/content/sample_data/image{x}/\"\n",
        "    destination_folder = '/content/sample_data/imagebig'\n",
        "\n",
        "    try:\n",
        "        with open(url_file_path, 'r') as url_file:\n",
        "            file_content = url_file.read()\n",
        "\n",
        "            urls = file_content.split('https')\n",
        "            urls = ['https' + url for url in urls if url.endswith('.tif') or url.endswith('.webp')]\n",
        "\n",
        "            count = len(urls)\n",
        "            with ThreadPoolExecutor(max_workers=64) as executor:\n",
        "                futures = [executor.submit(download, url, output_folder_path) for url in urls]\n",
        "                for future in as_completed(futures):\n",
        "                    future.result()\n",
        "\n",
        "        print(f\"Downloaded {count} files for image{x}.\")\n",
        "\n",
        "        source_folder = output_folder_path\n",
        "        destination_folder = os.path.join(destination_folder, '')\n",
        "        zip_filename = f\"image{x}.zip\"\n",
        "        zip_filepath = os.path.join(destination_folder, zip_filename)\n",
        "\n",
        "        with zipfile.ZipFile(zip_filepath, 'w') as myzip:\n",
        "            for filename in os.listdir(source_folder):\n",
        "                file_path = os.path.join(source_folder, filename)\n",
        "                myzip.write(file_path, filename)\n",
        "\n",
        "        print(\"Files have been successfully zipped for image{x} to\", zip_filepath)\n",
        "\n",
        "        source_file = zip_filepath\n",
        "        destination_folder = '/content/drive/MyDrive'\n",
        "\n",
        "        shutil.copy(source_file, destination_folder)\n",
        "        print(f\"Zip file for image{x} has been successfully copied to Google Drive folder.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url_file_path}: {e}\")"
      ],
      "metadata": {
        "id": "b8ZYqDzXSVqH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}